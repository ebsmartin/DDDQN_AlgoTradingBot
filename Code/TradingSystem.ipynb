{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35868\\3955130631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Torch imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_load_library_flags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibraryExW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0x00001100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mlast_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_last_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlast_error\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m126\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from time import time\n",
    "import argparse\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, get_rank, get_world_size, destroy_process_group\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import classes\n",
    "from Agent import Agent\n",
    "from CryptoData import CryptoData\n",
    "from DataVisualizer import DataVisualizer\n",
    "\n",
    "def setup_distributed():\n",
    "    # Parse command line arguments for 'rank' and 'world_size'\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--local_rank\", type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Initialize the process group\n",
    "    dist.init_process_group(backend='nccl', init_method='env://')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "\n",
    "\n",
    "class TradingSystem:\n",
    "    def __init__(self, initial_investment=10000, num_episodes=10, local_rank=0):\n",
    "        self.local_rank = local_rank\n",
    "        self.INITIAL_INVESTMENT = initial_investment\n",
    "        self.NUM_EPISODES = num_episodes\n",
    "        self.trading_agent = None\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.train_close = None\n",
    "        self.test_close = None\n",
    "        self.data_visualizer = None\n",
    "\n",
    "    def manual_data_partition(self, data):\n",
    "        total_size = len(data)\n",
    "        per_gpu = total_size // dist.get_world_size()\n",
    "        start = self.local_rank * per_gpu\n",
    "        end = start + per_gpu if self.local_rank < dist.get_world_size() - 1 else total_size\n",
    "        return data[start:end]\n",
    "\n",
    "    def load_data(self):\n",
    "        crypto_data = CryptoData()\n",
    "        full_train_df, full_test_df, train_close, test_close = crypto_data.get_precollected_data(split_ratio=0.8)\n",
    "\n",
    "        # Partition data for distributed training\n",
    "        self.train_df = self.manual_data_partition(full_train_df)\n",
    "        self.test_df = self.manual_data_partition(full_test_df)\n",
    "        self.train_close = self.manual_data_partition(train_close)\n",
    "        self.test_close = self.manual_data_partition(test_close)\n",
    "\n",
    "    def setup_trading_agent(self):\n",
    "        self.trading_agent = Agent(self.train_df.shape, self.NUM_EPISODES, self.window_size) \n",
    "        if os.path.exists(\"Output/online_model/model.pt\"):\n",
    "            print(\"Loading the model\")\n",
    "            self.trading_agent.load_model()\n",
    "        else:\n",
    "            print(\"No model found, training from scratch\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.trading_agent.model = self.trading_agent.model.cuda(self.local_rank)\n",
    "        self.trading_agent.model = DDP(self.trading_agent.model, device_ids=[self.local_rank])\n",
    "\n",
    "    # Curriculum 1 \n",
    "    def train(self):\n",
    "        episode_mem = [{\"Actions\": [], \"Inventory Size\": [], \"Portfolio Value\": [], \"Realized Profit\": [], \"Reward\": [], \"Done\": [], \"Epsilon\": [], \"MSE Loss\": []} for _ in range(self.NUM_EPISODES)]\n",
    "        t0 = time()\n",
    "        for s in range(self.NUM_EPISODES):\n",
    "            print(f\"\\n===== Episode {s + 1} / {self.NUM_EPISODES} =====\")\n",
    "            self.trading_agent.inventory = []\n",
    "            state = self.trading_agent.get_state(0, self.train_df)\n",
    "            balance = self.INITIAL_INVESTMENT\n",
    "            portfolio_value_usd = 0\n",
    "            self.trading_agent.portfolio = [0, self.INITIAL_INVESTMENT, portfolio_value_usd, 0]\n",
    "            done = False\n",
    "            for t in range(len(self.train_df) - 1):\n",
    "                if done:\n",
    "                    break\n",
    "                action = self.trading_agent.get_action(state)\n",
    "                next_state = self.trading_agent.get_state(t + 1, self.train_df)\n",
    "                reward = self.trading_agent.trade(t, action, self.train_df, self.train_close, self.INITIAL_INVESTMENT, trading_fee_rate=0.05)\n",
    "                balance += reward\n",
    "                done = balance < self.train_close[\"Close\"].iloc[t]\n",
    "                self.trading_agent.memory.add_exp(state, action, reward, next_state, done)\n",
    "                loss = self.trading_agent.train() or 0\n",
    "                state = next_state\n",
    "                \n",
    "                # Corrected dictionary update part\n",
    "                episode_mem[s][\"Actions\"].append(int(action))\n",
    "                episode_mem[s][\"Inventory Size\"].append(len(self.trading_agent.inventory))\n",
    "                episode_mem[s][\"Portfolio Value\"].append(balance + self.train_close[\"Close\"].iloc[t] * len(self.trading_agent.inventory) - sum(self.trading_agent.inventory) - self.INITIAL_INVESTMENT)\n",
    "                episode_mem[s][\"Realized Profit\"].append(balance - self.INITIAL_INVESTMENT)\n",
    "                episode_mem[s][\"Reward\"].append(reward)\n",
    "                episode_mem[s][\"Done\"].append(done)\n",
    "                episode_mem[s][\"Epsilon\"].append(self.trading_agent.epsilon)\n",
    "                episode_mem[s][\"MSE Loss\"].append(loss)\n",
    "\n",
    "        with open('Output/training_scores.out', 'a') as f:\n",
    "            \n",
    "            f.write(f\"EPISODE {s} (runtime: {time() - t0})   | Portfolio Value is {round(episode_mem[s]['Portfolio Value'][-1], 3)} Epsilon is {round(self.trading_agent.epsilon, 3)}   |   MSE Loss is {round(episode_mem[s]['MSE Loss'][-1], 3)}\\n\")\n",
    "        with open(\"Output/episode_mem.json\", 'w') as f:\n",
    "            json.dump(episode_mem, f)\n",
    "\n",
    "    def test(self):\n",
    "        testing_mem = {\"Actions\": [], \"Inventory Size\": [], \"Portfolio Value\": [], \"Realized Profit\": [], \"Reward\": [], \"Done\": []}\n",
    "        t0 = time()\n",
    "        self.trading_agent.epsilon = 0\n",
    "        self.trading_agent.inventory = []\n",
    "        state = self.trading_agent.get_state(0, self.test_df)\n",
    "        balance = self.INITIAL_INVESTMENT\n",
    "        portfolio_value_usd = 0\n",
    "        self.trading_agent.portfolio = [0, self.INITIAL_INVESTMENT, portfolio_value_usd, 0]\n",
    "\n",
    "        done = False\n",
    "        for t in range(len(self.test_df) - 1):\n",
    "            if done:\n",
    "                print(\"Done with testing\")\n",
    "                break\n",
    "            action = self.trading_agent.get_action(state)\n",
    "            next_state = self.trading_agent.get_state(t + 1, self.test_df)\n",
    "            reward = self.trading_agent.trade(t, action, self.test_df, self.test_close, self.INITIAL_INVESTMENT, trading_fee_rate=0.05)\n",
    "            balance += reward\n",
    "            done = balance < self.test_close[\"Close\"].iloc[t]\n",
    "            state = next_state\n",
    "            testing_mem.update({\n",
    "                \"Actions\": int(action),\n",
    "                \"Inventory Size\": len(self.trading_agent.inventory),\n",
    "                \"Portfolio Value\": float(balance + self.test_close[\"Close\"].iloc[t] * len(self.trading_agent.inventory) - sum(self.trading_agent.inventory)) - self.INITIAL_INVESTMENT,\n",
    "                \"Realized Profit\": float(balance - self.INITIAL_INVESTMENT),\n",
    "                \"Reward\": float(reward),\n",
    "                \"Done\": bool(done)\n",
    "            })\n",
    "\n",
    "        if dist.rank == 0:\n",
    "            with open('Output/testing_scores.out', 'a') as f:\n",
    "                f.write(f\"TESTING (runtime: {time() - t0})   |  Portfolio Value is {round(testing_mem['Portfolio Value'][-1], 3)}\\n\")\n",
    "            with open(\"Output/testing_mem.json\", 'w') as f:\n",
    "                json.dump(testing_mem, f)\n",
    "\n",
    "    def run(self):\n",
    "        print(\"PyTorch version \" + torch.__version__)\n",
    "        print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "        # grab the gpu id if available\n",
    "        print(\"GPU available: \", torch.cuda.is_available())\n",
    "        print(\"GPU device: \", torch.cuda.get_device_name(0))\n",
    "        print(\"GPU device count: \", torch.cuda.device_count())\n",
    "        print(\"GPU device index: \", torch.cuda.current_device())\n",
    "\n",
    "        print(torch.cuda.is_available())\n",
    "\n",
    "        setup_distributed()\n",
    "\n",
    "        self.load_and_prepare_data()\n",
    "        self.setup_trading_agent()\n",
    "        self.train()\n",
    "        self.test()\n",
    "\n",
    "        # Only save models or log information from one process to avoid conflicts\n",
    "        if dist.get_rank() == 0:\n",
    "            self.trading_agent.save_model()\n",
    "            print(\"Model saved\")\n",
    "\n",
    "        self.data_visualizer = DataVisualizer(self.train_close, self.test_close)\n",
    "        self.data_visualizer.visualize_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = setup_distributed()\n",
    "    trading_system = TradingSystem(local_rank=args.local_rank)  # Pass local_rank to TradingSystem\n",
    "    trading_system.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_AI_RL_20230410",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
